# -*- coding: utf-8 -*-
"""app

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10bfF6zTGzf0sLwg02dLYkT7IoBG3MQ2i
"""



import streamlit as st
import cv2
import tempfile
import os
import numpy as np
from ultralytics import YOLO

# --- Page Config (Must be first) ---
st.set_page_config(
    page_title="Neuro-Gait Analyzer",
    page_icon="ðŸ§ ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- Custom CSS for "Medical" Look ---
st.markdown("""
    <style>
    .main {
        background-color: #0e1117;
    }
    h1 {
        color: #ff4b4b; 
        text-align: center;
    }
    .stButton>button {
        width: 100%;
        background-color: #ff4b4b;
        color: white;
    }
    .metric-card {
        background-color: #262730;
        padding: 20px;
        border-radius: 10px;
        text-align: center;
    }
    </style>
    """, unsafe_allow_html=True)

# --- Header Section ---
col1, col2, col3 = st.columns([1, 6, 1])
with col2:
    st.title("ðŸ§  Neuro-Gait Analyzer")
    st.markdown("<h3 style='text-align: center; color: white;'>AI-Powered Early Parkinson's Detection</h3>", unsafe_allow_html=True)
    st.markdown("---")

# --- Sidebar ---
with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/8815/8815112.png", width=100)
    st.header("Control Panel")
    confidence_threshold = st.slider("AI Confidence Threshold", 0.0, 1.0, 0.5)
    
    st.info("â„¹ï¸ **Project Info**\n\nThis system uses **YOLOv8-Pose** to track gait anomalies (freezing/tremors) associated with Parkinson's Disease.")
    st.markdown("---")
    st.markdown("**Developed by:** Fahad Ijaz")

# --- Model Loading ---
@st.cache_resource
def load_model():
    return YOLO('yolov8n-pose.pt')

model = load_model()

# --- Main Interface ---
st.write("### ðŸ“‚ Upload Patient Data")

# Create two tabs: Upload vs Demo
tab1, tab2 = st.tabs(["ðŸ“¤ Upload Video", "ðŸŽ¬ Try Demo Video"])

input_path = None

with tab1:
    uploaded_file = st.file_uploader("Choose a video file (MP4, AVI)", type=['mp4', 'avi'])
    if uploaded_file is not None:
        tfile = tempfile.NamedTemporaryFile(delete=False) 
        tfile.write(uploaded_file.read())
        input_path = tfile.name

with tab2:
    st.write("No video? No problem. Click below to load a clinical sample.")
    if st.button("Load Sample Patient Data"):
        # You need to upload a file named 'demo.mp4' to your GitHub for this to work!
        if os.path.exists("demo.mp4"):
            input_path = "demo.mp4"
        else:
            st.error("Demo file not found! Please upload 'demo.mp4' to your repository.")

# --- Processing Logic ---
if input_path:
    col1, col2 = st.columns(2)
    
    with col1:
        st.info("ðŸŽ¥ Original Patient Feed")
        st.video(input_path)

    if st.button("ðŸ” Run AI Diagnostics", type="primary"):
        st.write("---")
        st.write("### ðŸ©º Diagnostics Dashboard")
        
        # Placeholder for Metrics
        m1, m2, m3 = st.columns(3)
        with m1:
            st.metric(label="Tremor Frequency", value="Calculating...", delta=None)
        with m2:
            st.metric(label="Gait Stability Score", value="Analyzing...", delta=None)
        with m3:
            st.metric(label="Parkinson's Risk", value="Pending", delta=None)
            
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # Processing Setup
        cap = cv2.VideoCapture(input_path)
        output_path = "output_detected.mp4"
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
        
        frame_count = 0
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            
            # Run Inference
            results = model(frame, conf=confidence_threshold)
            annotated_frame = results[0].plot()
            out.write(annotated_frame)
            
            frame_count += 1
            if total_frames > 0:
                progress_bar.progress(min(frame_count / total_frames, 1.0))
                status_text.text(f"Processing Frame {frame_count}/{total_frames}")

        cap.release()
        out.release()
        
        # --- Final Dashboard Update ---
        progress_bar.empty()
        status_text.empty()
        
        # Display Results
        c1, c2 = st.columns([1, 1])
        with c1:
            st.success("âœ… Analysis Complete")
            st.video(output_path)
        
        with c2:
            st.warning("ðŸ“Š Clinical Insights")
            # These are currently dummy metrics for the UI demo. 
            # In the real version, you'd calculate these from your 'entropy_history'.
            st.metric(label="Tremor Frequency (Detected)", value="4.8 Hz", delta="High Risk")
            st.metric(label="Gait Stability Score", value="42/100", delta="-15% vs Norm")
            st.caption("The system detected consistent hesitation in the turning phase, correlating with prodromal Parkinsonian symptoms.")
